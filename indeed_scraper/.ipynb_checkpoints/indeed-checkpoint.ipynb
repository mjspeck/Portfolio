{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries: Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from random import seed\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from randomfunctions import print_cols\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./csvs/cleaned_data/clean_data.csv').drop('Unnamed: 0', axis=1)\n",
    "mean_sal = jobs['mean salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['median', '60_perc', '70_perc', '75_perc', '90_perc']:\n",
    "    exec(f'_{i}_target = jobs[\\'{i}_bool\\']')\n",
    "    jobs.drop(f'{i}_bool', axis=1, inplace=True)\n",
    "\n",
    "jobs.drop(['Salary', 'lower_sal_val', 'upper_sal_val'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.get_dummies(jobs, columns=['state', 'Search Term', 'Company'])\n",
    "salaries = jobs['mean salary']\n",
    "jobs.drop(['Location', 'mean salary'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(jobs, _median_target, test_size=0.2)\n",
    "orig_train_rows = X_train.shape[0]\n",
    "orig_test_rows = X_test.shape[0]\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(X_train['Job Title'])\n",
    "\n",
    "def use_cvec(data):\n",
    "    cvec_data = pd.DataFrame(cvec.transform(data['Job Title']).todense(),\n",
    "                           columns=cvec.get_feature_names(), index=data.index)\n",
    "\n",
    "    data = pd.concat([data.drop('Job Title', axis=1), cvec_data], axis=1)\n",
    "    return data\n",
    "    \n",
    "X_train = use_cvec(X_train)\n",
    "X_test = use_cvec(X_test)\n",
    "\n",
    "# Check that concatenation worked as expected\n",
    "assert orig_train_rows == X_train.shape[0]\n",
    "assert orig_test_rows == X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':range(50,501, 50),\n",
    "          'max_depth':range(50,301, 50),\n",
    "          'min_samples_split':range(2,20,2)\n",
    "         }    \n",
    "\n",
    "clf = RandomForestClassifier(warm_start=True)\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid=params, cv=10, verbose=2, n_jobs=-1)\n",
    "#grid.fit(X_train, y_train)\n",
    "#pickle.dump(grid, open('grid_rf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 300, 'min_samples_split': 2, 'n_estimators': 300}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8538461538461538\n",
      "Recall: 0.8450704225352113\n",
      "Precision: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "test_preds = grid.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "recall = recall_score(y_test, test_preds)\n",
    "precision = precision_score(y_test, test_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the slightly lower accuracy score on the test set, our model may be slightly overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.075333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.036172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.028646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.027984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "data         0.075333\n",
       "research     0.036172\n",
       "analyst      0.029542\n",
       "engineer     0.028646\n",
       "scientist    0.027984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(grid.best_estimator_.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's good that we can see the most important words, we cannot see in which direction these words push the salary (ie. we don't know whether word data indicates a job is likely to have a higher or lower salary). In order to get some interpretive value from this model, I decided to take the fifty most important words and look at whether the median value of listings with that word in them were above the median of all the job listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>word medians</th>\n",
       "      <th>word means</th>\n",
       "      <th>word effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.075333</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>136377.136598</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.036172</td>\n",
       "      <td>59669.5</td>\n",
       "      <td>71170.413265</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.029542</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>86242.512821</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.028646</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>139112.802632</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.027984</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>126089.186170</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>0.025557</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>149555.555556</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.025476</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150652.173913</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_        Jobspring Partners</th>\n",
       "      <td>0.024260</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>154880.952381</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.023179</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>137449.118421</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_'CA'</th>\n",
       "      <td>0.013878</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>137827.848739</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.013653</td>\n",
       "      <td>155350.0</td>\n",
       "      <td>157377.068182</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative</th>\n",
       "      <td>0.012451</td>\n",
       "      <td>172500.0</td>\n",
       "      <td>167055.555556</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_    Harnham</th>\n",
       "      <td>0.011796</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>186000.000000</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_'MD'</th>\n",
       "      <td>0.010096</td>\n",
       "      <td>59339.0</td>\n",
       "      <td>66789.351852</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_    Averity</th>\n",
       "      <td>0.009875</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>178194.444444</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_        Huxley Associates</th>\n",
       "      <td>0.008879</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>158125.000000</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>0.008714</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>131673.913043</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>0.007792</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>173655.461538</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_        Workbridge Associates</th>\n",
       "      <td>0.007230</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>146153.846154</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Search Term_Santa Clara, CA</th>\n",
       "      <td>0.006822</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>152894.736842</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       importance  word medians  \\\n",
       "data                                     0.075333      132500.0   \n",
       "research                                 0.036172       59669.5   \n",
       "analyst                                  0.029542       75000.0   \n",
       "engineer                                 0.028646      135000.0   \n",
       "scientist                                0.027984      125000.0   \n",
       "machine                                  0.025557      150000.0   \n",
       "learning                                 0.025476      150000.0   \n",
       "Company_        Jobspring Partners       0.024260      157500.0   \n",
       "senior                                   0.023179      135000.0   \n",
       "state_'CA'                               0.013878      145000.0   \n",
       "science                                  0.013653      155350.0   \n",
       "quantitative                             0.012451      172500.0   \n",
       "Company_    Harnham                      0.011796      170000.0   \n",
       "state_'MD'                               0.010096       59339.0   \n",
       "Company_    Averity                      0.009875      195000.0   \n",
       "Company_        Huxley Associates        0.008879      160000.0   \n",
       "software                                 0.008714      130000.0   \n",
       "director                                 0.007792      175000.0   \n",
       "Company_        Workbridge Associates    0.007230      132500.0   \n",
       "Search Term_Santa Clara, CA              0.006822      150000.0   \n",
       "\n",
       "                                          word means word effect  \n",
       "data                                   136377.136598           +  \n",
       "research                                71170.413265           -  \n",
       "analyst                                 86242.512821           -  \n",
       "engineer                               139112.802632           +  \n",
       "scientist                              126089.186170           +  \n",
       "machine                                149555.555556           +  \n",
       "learning                               150652.173913           +  \n",
       "Company_        Jobspring Partners     154880.952381           +  \n",
       "senior                                 137449.118421           +  \n",
       "state_'CA'                             137827.848739           +  \n",
       "science                                157377.068182           +  \n",
       "quantitative                           167055.555556           +  \n",
       "Company_    Harnham                    186000.000000           +  \n",
       "state_'MD'                              66789.351852           -  \n",
       "Company_    Averity                    178194.444444           +  \n",
       "Company_        Huxley Associates      158125.000000           +  \n",
       "software                               131673.913043           +  \n",
       "director                               173655.461538           +  \n",
       "Company_        Workbridge Associates  146153.846154           +  \n",
       "Search Term_Santa Clara, CA            152894.736842           +  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = feature_importances.head(50).index.tolist()\n",
    "\n",
    "important_features_df = pd.DataFrame(feature_importances.head(50))\n",
    "\n",
    "imp2 = []\n",
    "for i in important_features:\n",
    "    imp2.append(str(i))\n",
    "\n",
    "# Create column with boolean values, representing whether the boolean\n",
    "# or dummy variable was above 0.\n",
    "for i in imp2:\n",
    "    X_train[i + ' bool'] = X_train[i] > 0\n",
    "\n",
    "word_medians = []\n",
    "word_means = []\n",
    "for i in imp2:\n",
    "    word_medians.append(np.median(jobs2.iloc[X_train.index][X_train[i + ' bool'] == True]['mean salary']))\n",
    "    word_means.append(np.mean(jobs2.iloc[X_train.index][X_train[i + ' bool'] == True]['mean salary']))\n",
    "\n",
    "important_features_df['word medians'] = word_medians\n",
    "important_features_df['word means'] = word_means\n",
    "\n",
    "median_effect = []\n",
    "for i in important_features_df['word medians']:\n",
    "    if i > 108607.5:\n",
    "        median_effect.append('+')\n",
    "    else:\n",
    "        median_effect.append('-')\n",
    "\n",
    "important_features_df['word effect'] = median_effect\n",
    "important_features_df.to_csv('./csvs/cleaned_data/important_features.csv')\n",
    "\n",
    "important_features_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important things we see here is that data is the most important feature in our model. This suggests not only that several non-data-related job listings come up when searching for data scientist positions on Indeed, but also that these positions are significantly lower paying than data and machine learning-related ones. Unsurprisingly, both 'machine' and 'learning' are also words that indicate high-paying jobs. We'll perform some hypothesis tests soon to confirm these hypotheses."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Misc",
   "language": "python",
   "name": "misc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
